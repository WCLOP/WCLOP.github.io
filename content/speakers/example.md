---
name: Example Speaker
link: https://github.com/sshwy
description: An Example Speaker
image: https://cn.gravatar.com/avatar/6a0315b48aabeb781bc8ef8ec656100e?d=mm&s=256
---

# Talk Title

Aria Glasses: An open-science wearable device for egocentric multi-modal AI research

# Talk Description

Augmented reality (AR) glasses will profoundly re-shape how we design assistive AI technolgoies, including healthcare robotics, by harnessing human experience and training powerful AI models using egocentric data sources. We introduce Aria, the all-day wearable, socially acceptable form-factor glasses to support always available, context-aware and personalized AI applications. Its industry-leading hardware specs, multi-modal data recording and streaming features, along with open-source software, datasets and community, make Aria the go-to platform for egocentric AI research and are quickly accelerating this emerging research field. In this talk, I will give an overview of the Aria ecosystem, recent advances in state-of-the-art egocentric machine perception, available open-source Aria software tools, as well as discussing the challenges and opportunities related to wearable/healthcare robotics research.

# Speaker Bio

Dr. Zijian Wang is a Research Engineer at Metaâ€™s Reality Lab Research division. His research interests include Augmented Reality (AR) glasses, 3D computer vision, contextual AI, hardware-software co-optimization, and robotics. Prior to joining Meta, he obtained his Ph.D. degree in 2019 advised by Prof. Mac Schwager from Stanford University, where he worked on planning and control for multi-robot systems.